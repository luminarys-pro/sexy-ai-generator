# ---------------- streamlit_app.py (Versi√≥n Final de Producci√≥n) ----------------

from __future__ import annotations
import streamlit as st
import google.generativeai as genai
import json
import os

# ---------- LISTAS DE OPCIONES Y CONSTANTES ----------
ALL_TAGS = [
    "Edad: Teen (18+)", "Edad: Joven (20-29)", "Edad: MILF (30-45)", "Edad: Madura/Cougar (45+)", "Cuerpo: Petite/Delgada", "Cuerpo: Curvy/Gruesa (Thick)", "Cuerpo: BBW/Talla Grande", "Cuerpo: Atl√©tico/Fitness", "Cuerpo: Musculosa", "Cabello: Rubia", "Cabello: Morena", "Cabello: Pelirroja", "Cabello: Pelo Negro", "Etnia: Latina", "Etnia: Asi√°tica", "Etnia: √âbano (Ebony)", "Etnia: India", "Etnia: Blanca/Cauc√°sica", "Rasgos: Tatuajes", "Rasgos: Piercings", "Rasgos: Busto Generoso", "Rasgos: Busto Peque√±o", "Rasgos: Pechos Naturales", "Rasgos: Trasero Grande", "Participantes: Solo (Chica)", "Participantes: Pareja (Chica/Chico)", "Participantes: Pareja (Chica/Chica)", "Pr√°ctica: Sexo Anal", "Pr√°ctica: Sexo Oral", "Pr√°ctica: Doble Penetraci√≥n", "Pr√°ctica: Creampie", "Pr√°ctica: Squirt", "Pr√°ctica: Masturbaci√≥n", "Pr√°ctica: BDSM", "Pr√°ctica: Bondage", "Pr√°ctica: Sumisi√≥n", "Pr√°ctica: Dominaci√≥n", "Fetiche: L√°tex", "Fetiche: Cuero (Leather)", "Fetiche: Tacones (Heels)", "Fetiche: Lencer√≠a", "Rol: Madrastra/Padrastro", "Rol: Hermanastra/o", "Rol: Profesora/Estudiante", "Rol: Jefa/Empleado", "Rol: Doctora/Enfermera", "Escenario: P√∫blico", "Escenario: Oficina", "Escenario: Casting/Entrevista", "Escenario: Masaje", "Escenario: Fiesta", "Escenario: C√°mara Esp√≠a (Spycam)", "Parodia: Cosplay", "Estilo: Amateur / Casero", "Estilo: POV (Punto de Vista)",
]
INTENSITY_LEVELS = ("Neutral", "Coqueto", "Sumisa", "Dominante", "Fetichista", "Femdom")
DM_SCENARIOS = ("Mensaje de Bienvenida (Nuevo Fan)", "Oferta Especial (Venta de PPV)", "Anuncio de Live Stream", "Reactivaci√≥n (Fan Inactivo)", "Agradecimiento (Fan Destacado)")
DEFAULT_PERSONA = "Eres una IA que encarna el rol de una experta en psicolog√≠a sexual y socioemocional, psicolog√≠a de ventas y estrategia de marketing. Eres una creadora de contenido veterana y exitosa."
LANGUAGE_EMOJI_MAP = {"Espa√±ol": "üá™üá∏", "Ingl√©s": "üá∫üá∏", "Franc√©s": "üá´üá∑", "Portugu√©s": "üáµüáπüáßüá∑", "Neerland√©s": "üá≥üá±"}
AVAILABLE_LANGUAGES = list(LANGUAGE_EMOJI_MAP.keys())

# ---------- CONFIGURACI√ìN P√ÅGINA ----------
st.set_page_config(page_title="Luminarys AI Assistant", page_icon="‚ú®", layout="wide")

# --- INICIALIZACI√ìN DE LA MEMORIA DE SESI√ìN ---
session_keys = {
    'profiles': {}, 'selected_profile_name': "-- Ninguno --", 'last_desc_generation': [],
    'dm_conversation_history': [], 'dm_context': {}, 'dm_reply_suggestions': []
}
for key, default_value in session_keys.items():
    if key not in st.session_state:
        st.session_state[key] = default_value

# ---------- CLAVE GEMINI ----------
try:
    api_key = os.environ['GEMINI_API_KEY']
    genai.configure(api_key=api_key)
except KeyError:
    st.error("No se encontr√≥ la clave de API de Gemini. Aseg√∫rate de a√±adirla a los 'Secrets'.")
    st.stop()

# ==================== FUNCIONES DE L√ìGICA Y CALLBACKS ====================
def get_model_response(prompt_text):
    try:
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        response = model.generate_content(prompt_text, generation_config=genai.types.GenerationConfig(temperature=1.0))
        if hasattr(response, 'text') and response.text:
            cleaned_text = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(cleaned_text)
        else:
            st.warning("‚ö†Ô∏è La IA no gener√≥ una respuesta. Esto puede ocurrir debido a los filtros de seguridad. Intenta con una combinaci√≥n de etiquetas diferente.", icon="ü§ñ")
            return None
    except Exception as e:
        st.error(f"Error al procesar la respuesta de la IA: {e}")
        return None

def save_new_profile():
    name = st.session_state.get("profile_name_input", "").strip()
    desc = st.session_state.get("profile_desc_input", "").strip()
    if name and desc:
        st.session_state.profiles[name] = {"description": desc, "tags": st.session_state.get("profile_tags_input", []), "intensity": st.session_state.get("profile_intensity_input", "Coqueto")}
        st.session_state.selected_profile_name = name
        st.toast(f"¬°Perfil '{name}' guardado!", icon="‚úÖ")
    else:
        st.toast("El nombre y la descripci√≥n son obligatorios.", icon="‚ö†Ô∏è")

def delete_active_profile():
    active_profile = st.session_state.selected_profile_name
    if active_profile in st.session_state.profiles:
        del st.session_state.profiles[active_profile]
        st.session_state.selected_profile_name = "-- Ninguno --"
        st.toast(f"Perfil '{active_profile}' eliminado.", icon="üóëÔ∏è")

# ==================== BARRA LATERAL (SIDEBAR) ====================
with st.sidebar:
    st.title("üé≠ Gestor de Perfiles")
    profile_names = ["-- Ninguno --"] + list(st.session_state.profiles.keys())
    st.selectbox("Cargar Perfil", options=profile_names, key='selected_profile_name')
    st.markdown("---")
    with st.expander("‚ûï Crear Nuevo Perfil"):
        with st.form("new_profile_form"):
            st.text_input("Nombre del Perfil*", key="profile_name_input")
            st.text_area("Descripci√≥n de la Personalidad*", height=200, key="profile_desc_input", placeholder="Ej: Eres una diosa dominante...")
            profile_tags_input = st.multiselect("Etiquetas Predeterminadas", options=ALL_TAGS, key="profile_tags_input")
            st.caption(f"Seleccionadas: {len(profile_tags_input)}")
            st.selectbox("Intensidad Predeterminada", options=INTENSITY_LEVELS, index=1, key="profile_intensity_input")
            st.form_submit_button("Guardar Perfil", on_click=save_new_profile)

    if st.session_state.selected_profile_name != "-- Ninguno --":
        st.markdown("---")
        st.button(f"üóëÔ∏è Eliminar Perfil '{st.session_state.selected_profile_name}'", on_click=delete_active_profile, use_container_width=True, type="primary")

# ==================== P√ÅGINA PRINCIPAL ====================
st.title("üíå AI Content Assistant")
st.markdown("by **Luminarys Production**")

active_profile_data = st.session_state.profiles.get(st.session_state.get('selected_profile_name', '-- Ninguno --'), {})
persona_clause = active_profile_data.get('description', DEFAULT_PERSONA)
default_tags = active_profile_data.get('tags', [])
default_intensity = active_profile_data.get('intensity', 'Coqueto')

tab_desc, tab_dm = st.tabs(["üìù **Generador de Descripciones**", "üí¨ **Asistente de DMs**"])

with tab_desc:
    st.header("Crea Descripciones para tus Posts")
    desc_col1, desc_col2 = st.columns([1, 1.2])

    with desc_col1:
        creator_username = st.text_input("Tu nombre de usuario (ej: @Martinaoff)", key="desc_username")
        desc_physical_features = st.text_input("Tus caracter√≠sticas f√≠sicas (opcional)", placeholder="Ej: pelo rojo, ojos verdes", key="desc_phys")
        
        desc_default_tags = default_tags[:10]
        desc_selected_tags = st.multiselect("Elige de 2 a 10 etiquetas", options=ALL_TAGS, max_selections=10, default=desc_default_tags, key="desc_tags")
        st.caption(f"Seleccionadas: {len(desc_selected_tags)} / 10")

        safe_intensity_index = INTENSITY_LEVELS.index(default_intensity) if default_intensity in INTENSITY_LEVELS else 1
        desc_intensity = st.selectbox("Nivel de intensidad", options=INTENSITY_LEVELS, index=safe_intensity_index, key="desc_intensity")
        
        desc_output_languages = st.multiselect("Idiomas de salida", options=AVAILABLE_LANGUAGES, default=["Espa√±ol", "Ingl√©s"], key="desc_langs")
        desc_num_messages = st.slider("Cantidad de ideas a generar", 1, 5, 3, key="desc_slider")

        if st.button("üöÄ Generar Descripciones", key="gen_desc", use_container_width=True):
            if len(desc_selected_tags) < 2: st.warning("Por favor, selecciona al menos 2 etiquetas.")
            elif not desc_output_languages: st.error("Por favor, selecciona al menos un idioma de salida.")
            else:
                task_description = f"Tu Misi√≥n es generar {desc_num_messages} ideas de descripciones para un post."
                language_clause = ", ".join(desc_output_languages)
                tags_clause = ", ".join(desc_selected_tags)
                prompt = f"**REGLA M√ÅXIMA: Eres un modelo de LENGUAJE. NO generas im√°genes. Tu √öNICA funci√≥n es generar TEXTO en el formato JSON especificado.**\n\n**Tu Identidad y Rol:** {persona_clause} Tu personalidad debe ser `{desc_intensity}`. Act√∫as desde la perspectiva de una persona definida por las etiquetas: `{tags_clause}`. Si se especifican caracter√≠sticas f√≠sicas (`{desc_physical_features or 'No especificadas'}`), incorp√≥ralas de forma aut√©ntica.\n**{task_description}**\n**Instrucci√≥n Clave:** Cada vez que generes, produce un lote de ideas COMPLETAMENTE NUEVO.\n**Manual de Estilo:** 1. **Mostrar, no Decir**. 2. **CERO CLICH√âS y CERO HASHTAGS**. 3. **ADAPTACI√ìN CULTURAL AVANZADA** para el ingl√©s. 4. **FORMATO JSON ESTRICTO:** Tu √∫nica respuesta debe ser un objeto JSON con la clave 'messages' (lista de ideas, cada una con 'id' y lista de 'outputs' por idioma).\nGenera el contenido."
                with st.spinner("Creando descripciones √∫nicas..."):
                    data = get_model_response(prompt)
                    if data and isinstance(data, dict):
                        st.session_state.last_desc_generation = data.get("messages", [])

    with desc_col2:
        st.subheader("Resultados Listos para Copiar")
        if not st.session_state.last_desc_generation:
            st.info("Aqu√≠ aparecer√°n las descripciones generadas.")
        
        for i, item in enumerate(st.session_state.last_desc_generation):
            if not isinstance(item, dict): continue
            unique_id = item.get('id', i)
            st.markdown(f"**Idea #{unique_id}**")
            
            outputs = item.get("outputs", [])
            base_text_for_variation = outputs[0].get('text') if outputs and isinstance(outputs[0], dict) else ""

            if isinstance(outputs, list):
                for output in outputs:
                    if isinstance(output, dict):
                        lang, text = output.get("language", ""), output.get("text", "")
                        emoji = LANGUAGE_EMOJI_MAP.get(lang, "üè≥Ô∏è")
                        display_text = f"{creator_username.strip()}\n\n{text}" if creator_username else text
                        st.text_area(f"{emoji} {lang}", value=display_text, height=150, key=f"desc_output_{unique_id}_{lang}")
            
            if st.button("üîÑ Generar Variaci√≥n", key=f"var_desc_{unique_id}"):
                var_prompt = f"**Tu Rol:** Eres un experto en copywriting creativo.\n**Tu Tarea:** Toma el siguiente texto y reescr√≠belo. Mant√©n la idea central, el tono `{desc_intensity}` y las etiquetas `{', '.join(desc_selected_tags)}`, pero usa diferentes palabras y estructuras para crear una variaci√≥n fresca.\n**Texto Base:** \"{base_text_for_variation}\"\n**Instrucci√≥n de Idioma:** Genera la variaci√≥n para los idiomas: `{', '.join(desc_output_languages)}`.\n**Formato de Salida:** Devuelve un √öNICO objeto JSON que represente UNA SOLA idea de mensaje, con la estructura: {{\"messages\": [{{\"id\": \"{unique_id}-v\", \"outputs\": [...]}}]}}"
                with st.spinner("Refinando idea..."):
                    variation_data = get_model_response(var_prompt)
                    if variation_data and isinstance(variation_data.get("messages"), list):
                        st.session_state.last_desc_generation[i] = variation_data["messages"][0]
                        st.rerun()
            st.markdown("---")

with tab_dm:
    st.header("Gestiona tus Conversaciones con Fans")
    if not st.session_state.dm_conversation_history:
        st.subheader("1. Iniciar una Nueva Conversaci√≥n")
        dm_scenario = st.selectbox("Elige un escenario estrat√©gico", options=DM_SCENARIOS, key="dm_scenario")
        fan_username = st.text_input("Nombre de usuario del fan (opcional)", placeholder="@usuario", key="dm_fan_username")
        dm_default_tags = default_tags[:5]
        dm_tags = st.multiselect("Elige etiquetas para este DM", options=ALL_TAGS, max_selections=5, default=dm_default_tags, key="dm_tags")
        st.caption(f"Seleccionadas: {len(dm_tags)} / 5")
        safe_dm_intensity_index = INTENSITY_LEVELS.index(default_intensity) if default_intensity in INTENSITY_LEVELS else 1
        dm_intensity = st.selectbox("Intensidad del DM", options=INTENSITY_LEVELS, index=safe_dm_intensity_index, key="dm_intensity")
        
        if st.button("‚úçÔ∏è Generar Primer Mensaje"):
            st.session_state.dm_context = {"scenario": dm_scenario, "tags": dm_tags, "intensity": dm_intensity, "username": fan_username, "persona": persona_clause}
            first_message_prompt = f"Tu Rol: {persona_clause}\nTu Misi√≥n: Escribe el PRIMER mensaje para un fan en el escenario '{dm_scenario}', con un tono '{dm_intensity}' y usando las etiquetas '{', '.join(dm_tags)}' como inspiraci√≥n. El fan es '{fan_username if fan_username else 'un nuevo fan'}'. El mensaje debe ser corto, personal y dise√±ado para obtener una respuesta. Devuelve solo el texto del mensaje, sin comillas."
            with st.spinner("Creando el rompehielos perfecto..."):
                model = genai.GenerativeModel('gemini-1.5-flash-latest')
                response = model.generate_content(first_message_prompt)
                st.session_state.dm_conversation_history.append({"role": "assistant", "parts": [response.text.strip()]})
                st.rerun()
    else:
        st.subheader("2. Conversaci√≥n Activa")
        chat_container = st.container(height=300)
        with chat_container:
            for msg in st.session_state.dm_conversation_history:
                with st.chat_message("user" if msg["role"] == "user" else "assistant"):
                    st.write(msg["parts"][0])
        
        st.subheader("3. Asistente de Respuesta")
        if st.session_state.dm_reply_suggestions:
            st.markdown("üí° **Sugerencias de Respuesta:**")
            for i, suggestion_item in enumerate(st.session_state.dm_reply_suggestions):
                if not isinstance(suggestion_item, dict): continue
                suggestion_id = suggestion_item.get('id', i)
                st.markdown(f"**Opci√≥n #{suggestion_id}**")
                
                sugg_col1, sugg_col2 = st.columns([4, 1])
                with sugg_col1:
                    for output in suggestion_item.get("outputs", []):
                        if isinstance(output, dict):
                            lang, text = output.get("language", ""), output.get("text", "")
                            emoji = LANGUAGE_EMOJI_MAP.get(lang, "üè≥Ô∏è")
                            st.text_area(f"{emoji} {lang}", value=text, height=100, key=f"sugg_{suggestion_id}_{lang}")
                
                with sugg_col2:
                    if st.button("‚úÖ Usar", key=f"use_sugg_{suggestion_id}", use_container_width=True):
                        # A√±ade solo el texto en el primer idioma al historial
                        first_text = suggestion_item.get("outputs", [{}])[0].get("text", "")
                        st.session_state.dm_conversation_history.append({"role": "assistant", "parts": [first_text]})
                        st.session_state.dm_reply_suggestions = []
                        st.rerun()
                    if st.button("üîÑ Variar", key=f"var_sugg_{suggestion_id}", use_container_width=True):
                        st.info("La funci√≥n de variar sugerencias de DM se activar√° en la pr√≥xima actualizaci√≥n.")
                st.markdown("---")
        
        with st.form("reply_form"):
            fan_reply = st.text_area("Pega aqu√≠ la respuesta del fan:", height=100, key="fan_reply_text")
            fan_lang = st.selectbox("Idioma del mensaje del fan:", options=AVAILABLE_LANGUAGES)
            dm_output_languages = st.multiselect("Generar respuestas en:", options=AVAILABLE_LANGUAGES, default=["Espa√±ol", "Ingl√©s"])
            submitted = st.form_submit_button("üí° Generar Sugerencias")
            if submitted and fan_reply:
                st.session_state.dm_conversation_history.append({"role": "user", "parts": [fan_reply]})
                context = st.session_state.dm_context
                history_for_prompt = "\n".join([f"{'Creadora' if m['role'] == 'assistant' else 'Fan'}: {m['parts'][0]}" for m in st.session_state.dm_conversation_history])
                
                # Pre-procesamiento del mensaje del fan
                pre_process_prompt = f"Eres un traductor de lenguaje expl√≠cito a sugerente. Reformula esta frase para que mantenga la intenci√≥n original pero sea menos directa y segura para una IA: \"{fan_reply}\". Devuelve solo la frase reformulada."
                model = genai.GenerativeModel('gemini-1.5-flash-latest')
                safe_reply_response = model.generate_content(pre_process_prompt)
                safe_fan_reply = safe_reply_response.text.strip()
                
                reply_prompt = f"Tu Rol: {context['persona']}. Tu Tono: {context['intensity']}.\nObjetivo: {context['scenario']}.\nHistorial: {history_for_prompt.replace(fan_reply, safe_fan_reply)}\n√öltimo mensaje del fan (en {fan_lang}): \"{safe_fan_reply}\"\nTu Misi√≥n: Genera 3 opciones de respuesta distintas y creativas. Genera una versi√≥n en cada uno de estos idiomas: {', '.join(dm_output_languages)}.\nFormato: JSON con clave 'messages' (lista de 3 ideas, cada una con 'id' y 'outputs').\nGenera las respuestas."
                
                with st.spinner("Analizando y creando respuestas..."):
                    data = get_model_response(reply_prompt)
                    if data:
                        st.session_state.dm_reply_suggestions = data.get("messages", [])
                st.rerun()

        if st.button("‚ùå Terminar y Empezar Nueva Conversaci√≥n"):
            st.session_state.dm_conversation_history.clear()
            st.session_state.dm_context.clear()
            st.session_state.dm_reply_suggestions.clear()
            st.rerun()

